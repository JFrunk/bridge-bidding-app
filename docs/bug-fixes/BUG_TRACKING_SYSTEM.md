# Bug Tracking System - Bridge Bidding Application
**Created:** 2025-10-18
**Purpose:** Centralized bug tracking with priority, status, and user testing instructions

---

## üìã How to Use This Document

When you report a bug in chat:
1. I will add it to this document under the appropriate priority section
2. Assign it a unique bug ID (BUG-XXX)
3. Create a test plan so you can verify the fix
4. Track status: üî¥ Active ‚Üí üîÑ In Progress ‚Üí ‚úÖ Fixed ‚Üí ‚úîÔ∏è Verified

**Color Key:**
- üî¥ **CRITICAL** - Production blocking, must fix immediately
- üü° **HIGH** - Should fix before launch, major impact
- üü¢ **MEDIUM** - Fix soon, moderate impact
- üü¢ **LOW** - Nice to have, minor impact
- ‚úÖ **FIXED** - Code fixed, awaiting verification
- ‚úîÔ∏è **VERIFIED** - User confirmed bug is resolved

---

## üî¥ CRITICAL BUGS (Production Blockers)

### BUG-C001: Login "Failed to Fetch" Error
**Status:** üî¥ Active
**Severity:** CRITICAL - Users cannot login
**Discovered:** 2025-10-18
**Area:** Authentication / Backend Connection
**Documentation:** [PRODUCTION_BUGS_AND_TEST_PLAN.md](PRODUCTION_BUGS_AND_TEST_PLAN.md#bug-010-login-screen-failed-to-fetch-error)

#### Problem
When users attempt to login via email authentication screen, they receive "Failed to fetch" error.

#### Symptoms
- Enter email ‚Üí Click "Continue" ‚Üí Error: "Failed to fetch"
- No network request reaches backend
- Cannot create accounts or login

#### Root Cause
Frontend expects backend on `http://localhost:5001` but backend may be running on `http://localhost:5000` (port mismatch).

#### How to Test if Bug is Fixed
```bash
# 1. Start backend
cd backend
python3 server.py
# Wait for: "Running on http://127.0.0.1:5000"

# 2. Check frontend .env file
cat frontend/.env
# Should show: REACT_APP_API_URL=http://localhost:5000

# 3. Start frontend
cd frontend
npm start

# 4. Try to login
# Open http://localhost:3000
# Click login button
# Enter email: test@example.com
# Click "Continue"
# ‚úÖ PASS: Login succeeds, no "Failed to fetch" error
# ‚ùå FAIL: Still shows "Failed to fetch"
```

#### Files Involved
- `frontend/src/contexts/AuthContext.jsx` (line 5) - API URL config
- `frontend/src/components/auth/SimpleLogin.jsx` (lines 14-50) - Login handler
- `backend/server.py` (lines 120-122) - Auth endpoints

---

### BUG-C002: DDS Crashes on macOS During Gameplay (Error Code -14)
**Status:** üî¥ Active
**Severity:** CRITICAL - System crash during gameplay
**Discovered:** 2025-10-18 at 18:17
**Area:** Card Play AI / DDS Integration
**Documentation:** [BUG_DDS_CRASH_2025-10-18.md](BUG_DDS_CRASH_2025-10-18.md)

#### Problem
DDS (Double Dummy Solver) crashes during active gameplay on macOS with Error Code -14 ("Too few cards" or invalid deal structure). System generates dump.txt crash file and game becomes unusable.

#### Symptoms
- Playing hand with Expert AI mode active
- Mid-game crash with DDS Error Code -14
- dump.txt file created in project root
- Complete game failure, no recovery

#### Root Cause
**Triple failure:**
1. **DDS initialized on macOS despite known instability** - server.py creates DDSPlayAI() at startup if endplay installed
2. **User can manually select Expert mode** - UI allows switching to Expert which uses unstable DDS
3. **Smart default may enable Expert** - Auto-detection enables Expert if DDS_AVAILABLE=True, even on macOS

**Known issue:** DDS is fundamentally unstable on macOS M1/M2 (40-60% success rate, segmentation faults)

#### Evidence
**dump.txt created Oct 18, 2025 at 18:17:**
```
Error code=-14
trump=H
first=N
[Deal with 4 hands showing invalid structure]
```

#### How to Test if Bug is Fixed
```bash
# Test 1: Verify DDS blocked on macOS
PYTHONPATH=backend python3 -c "
import platform
print(f'Platform: {platform.system()}')
from core.session_state import DEFAULT_AI_DIFFICULTY
print(f'Default AI: {DEFAULT_AI_DIFFICULTY}')
from server import DDS_AVAILABLE, ai_instances
print(f'DDS Available: {DDS_AVAILABLE}')
print(f'Expert AI: {ai_instances[\"expert\"].get_name()}')
"
# ‚úÖ PASS on macOS:
#    Platform: Darwin
#    Default AI: advanced
#    DDS Available: False
#    Expert AI: Minimax AI (depth 4)

# Test 2: Play 10 hands with Expert mode
# Click "Expert" in AI difficulty selector
# Play 10 complete hands
# ‚úÖ PASS: All hands complete, no crashes, no dump.txt
# ‚ùå FAIL: Any DDS crash or dump.txt created

# Test 3: Verify production (Linux) still uses DDS
# Deploy to Linux staging
# Check Expert AI uses DDSPlayAI
# ‚úÖ PASS: Expert AI = "Double Dummy Solver AI"
```

#### Files Involved
- `backend/server.py` (lines 27-38, 66-73) - DDS initialization, AI instances
- `backend/core/session_state.py` (lines 47-72) - Smart default logic
- `backend/engine/play/ai/dds_ai.py` - DDS implementation

#### Fix Required
1. **Add platform detection** - Block DDS initialization on macOS
2. **Force Advanced default on macOS** - Override smart default
3. **Safe AI instances** - Never create DDSPlayAI on macOS
4. **UI indicator** - Show why Expert uses Minimax fallback

**Status:** ‚úÖ FIXED - Awaiting User Verification
**Fix Documentation:** [BUG_C002_FIX_SUMMARY.md](BUG_C002_FIX_SUMMARY.md)

#### Fix Implemented
1. ‚úÖ Platform detection blocks DDS on macOS (server.py)
2. ‚úÖ Force Advanced default on macOS (session_state.py)
3. ‚úÖ Safe AI initialization - never creates DDSPlayAI on macOS
4. ‚úÖ Clear logging explains why DDS disabled

#### Test Results (Automated)
```
‚úÖ PASS: DDS correctly disabled on macOS
‚úÖ PASS: Platform check correctly blocking DDS
‚úÖ PASS: Default correctly set to advanced
‚úÖ PASS: Expert using Minimax fallback (no DDS crashes)
```

#### User Verification Needed
Please test:
1. [ ] Restart backend server - verify "DDS DISABLED on Darwin" message
2. [ ] Check default AI is "advanced"
3. [ ] Select Expert mode and play 5-10 hands
4. [ ] Verify no crashes, no new dump.txt files
5. [ ] Mark as ‚úîÔ∏è VERIFIED if all tests pass

### BUG-C003: Gameplay Freezes on Last Trick ‚Äî Card Disappears
**Status:** ‚úÖ Fixed (awaiting verification)
**Severity:** CRITICAL - Game becomes unplayable mid-hand
**Discovered:** 2026-01-29
**Area:** Card Play / AI Loop / Trick Lifecycle

#### Problem
On trick 13 (final trick), a card played by North "disappears" ‚Äî removed from the hand but lost from the trick display. The game freezes with "Your turn to play from North (partner)!" but North has 0 cards remaining.

#### Symptoms
- North (declarer) plays a card on trick 13, but the trick shows only 3 cards
- Console shows: `current_trick` has 3 cards, `next_to_play: 'N'`, North has 0 cards
- AI loop fires with stale position (`W` instead of `N`), gets 403 from backend
- Game stuck in infinite render loop ‚Äî no score displayed

#### Root Cause (Three Interconnected Bugs)

**Bug 1: `clear-trick` has no safety guard (backend)**
The `/api/clear-trick` endpoint blindly sets `current_trick = []` with no validation. If called when the trick is incomplete (< 4 cards), it destroys cards already removed from player hands ‚Äî permanent card loss.

**Bug 2: Inconsistent user-turn check in card handlers (frontend)**
After a trick clears, card play handlers used a narrow formula:
```js
const nextIsUserTurn = next_to_play === 'S' ||
    (next_to_play === dummy && declarer === 'S');
```
This misses the single-player case where NS is declaring and North needs to play. The AI loop's comprehensive check handles this correctly, but the inconsistency causes a glitch cycle.

**Bug 3: AI loop useEffect has no cancellation (frontend)**
The AI loop fires `runAiPlay()` without a cleanup/cancellation mechanism. If the effect re-fires (due to `isPlayingCard` toggling), a stale invocation races with a fresh one, leading to duplicate API calls with wrong positions.

#### Fix Applied

1. **Backend safety guard** (`backend/server.py` ‚Äî `clear-trick` endpoint): Only clear if `len(current_trick) == 4`. Return 400 error if called mid-trick.

2. **Consistent user-turn helper** (`frontend/src/App.js`): Added `isNextPlayerUserControlled()` function using backend's `controllable_positions` from BridgeRulesEngine, with fallback matching the AI loop's comprehensive logic. Replaced all 7 inline checks.

3. **AbortController for AI loop** (`frontend/src/App.js`): Added `AbortController` pattern ‚Äî creates controller at effect start, checks `signal.aborted` before each API call, cleanup function calls `abort()` on re-fire/unmount.

#### Files Involved
- `backend/server.py` (clear-trick endpoint) - Safety guard against incomplete trick clearing
- `frontend/src/App.js` (isNextPlayerUserControlled helper) - Consistent single-player turn logic
- `frontend/src/App.js` (AI play loop useEffect) - AbortController cancellation pattern

#### How to Test if Bug is Fixed
1. Start backend and frontend locally
2. Play a hand where North is declarer (South is dummy)
3. Play through to trick 12-13
4. Verify: No cards disappear from the trick display
5. Verify: Score appears after trick 13 completes
6. Verify: No 403 errors in console
7. Check console for absence of stale-position API calls

#### User Verification Needed
Please test:
1. [ ] Play a full hand where NS is declaring (N or S is declarer)
2. [ ] Play through all 13 tricks ‚Äî verify no cards vanish
3. [ ] Verify score screen appears after trick 13
4. [ ] Check browser console for absence of 403 errors or stale AI calls
5. [ ] Mark as ‚úîÔ∏è VERIFIED if all tests pass

---

### BUG-C004: 12-Card Hand ‚Äî Stale play_state Causes Wrong Hands After New Deal
**Status:** üî¥ Active
**Severity:** CRITICAL - Corrupted game state, missing card, potentially all hands wrong
**Discovered:** 2026-02-01
**Area:** State Management / Deal Lifecycle / Play State Isolation

#### Problem
After playing a hand (or starting play phase) and then dealing a new hand, the `get-all-hands` endpoint returns hands from the **previous game's play state** instead of the fresh deal. This causes one or more positions to show fewer than 13 cards (observed: East with 12 cards), and ALL displayed hands may be from the wrong game entirely.

#### Symptoms
- East (or another position) shows only 12 cards after a new deal
- Console shows: `East hand length: 12` from `get-all-hands` response
- Other positions may show 13 cards but from the WRONG deal (stale data)
- Bidding happened on the correct new hand, but "Show All Hands" displays old hand data

#### Root Cause (Three Interconnected Bugs)

**Bug 1: `perform_new_deal()` does not reset `play_state` (server.py:820-855)**
When a new hand is dealt, `perform_new_deal()` creates new Hand objects for `state.deal` but never clears `state.play_state` from the previous hand. The existing `state.reset_hand()` method (session_state.py:122-128) correctly resets `play_state = None`, but `perform_new_deal()` doesn't call it.

**Bug 2: Play state shares Hand object references with deal (server.py:2951, 3097)**
When play begins, `hands[pos] = state.deal[full_name]` assigns the **same Hand object** (not a deep copy) to the play state. During play, `hand.cards.remove(card)` (server.py:3268, 3526) mutates the shared object, reducing card count in both `play_state.hands` AND `state.deal`.

**Bug 3: `get-all-hands` prioritizes stale play_state (server.py:2153)**
The endpoint checks `if state.play_state and state.play_state.hands` first, and if truthy, returns play state hands. After a new deal, this condition is still true (play_state was never cleared), so it returns old/mutated hands instead of the fresh deal.

#### Evidence

**Console capture (frontend):**
```
üì° Fetching from: https://app.mybridgebuddy.com/api/get-all-hands
üîç Detailed check - North hand length: 13
üîç Detailed check - East hand length: 12    ‚Üê MISSING CARD
üîç Detailed check - South hand length: 13
üîç Detailed check - West hand length: 13

East ‚ô†: 3 cards A 7 2
East ‚ô•: 3 cards Q 6 5
East ‚ô£: 3 cards J 7 5
East ‚ô¶: 3 cards K J 4
East total: 12 (should be 13)
```

**Production server logs (bridge-backend journal):**
```
‚úÖ Preserved original_deal with 52 total cards    ‚Üê play_state set on hand N
üÉè Dealt new hand. Dealer: E, Vul: NS             ‚Üê new deal (play_state NOT cleared)
üÉè East: 13 cards                                  ‚Üê backend dealt 13 correctly
... bidding proceeds on new hand ...
‚Üê get-all-hands called ‚Üí reads stale play_state ‚Üí returns 12-card East
```

#### Scenario That Triggers Bug
1. Play a hand (or click "Play This Hand" to start play phase)
2. Opening leader plays one card (e.g., East leads ‚Äî East now has 12 cards in shared Hand object)
3. Deal a new hand (click "Deal New Hand")
4. Bidding happens on the new hand (correctly, using fresh `state.deal`)
5. Click "Show All Hands" ‚Üí `get-all-hands` finds stale `play_state` ‚Üí returns old East hand with 12 cards

#### Fix Required (Three-Part)

1. **Reset play_state in `perform_new_deal()`** ‚Äî Add `state.play_state = None` and `state.original_deal = None` so stale play data doesn't persist across deals.

2. **Deep-copy Hand objects when initializing play state** ‚Äî At server.py:2951 and 3097, use `copy.deepcopy(state.deal[full_name])` instead of direct reference assignment. This prevents card removal during play from mutating `state.deal`.

3. **Add defensive card count validation in `get-all-hands`** ‚Äî Log a warning if any hand has fewer than 13 cards during bidding phase, to catch similar issues early.

#### Files Involved
- `backend/server.py` (line 820-855) ‚Äî `perform_new_deal()` missing play_state reset
- `backend/server.py` (line 2951) ‚Äî `start_play_phase()` shared Hand reference
- `backend/server.py` (line 3097) ‚Äî `play_random_hand()` shared Hand reference
- `backend/server.py` (line 2153) ‚Äî `get_all_hands()` stale play_state check
- `backend/server.py` (lines 3268, 3526) ‚Äî `hand.cards.remove(card)` mutates shared object
- `backend/core/session_state.py` (line 122-128) ‚Äî `reset_hand()` exists but not called

#### How to Test if Bug is Fixed
```bash
# 1. Start app
cd backend && source venv/bin/activate && python server.py
cd frontend && npm start

# 2. Deal a hand and start play phase
# Click "Deal New Hand" ‚Üí Complete bidding ‚Üí Click "Play This Hand"
# Play at least 1 trick (opening lead + 3 more cards)

# 3. Deal a NEW hand without finishing the previous one
# Click "Deal New Hand" again

# 4. After bidding completes on new hand, click "Show All Hands"
# ‚úÖ PASS: All 4 positions show exactly 13 cards
# ‚úÖ PASS: Hands match the current deal (not previous game)
# ‚ùå FAIL: Any position has fewer than 13 cards
# ‚ùå FAIL: Hands are from the previous game

# 5. Repeat 5 times with different play/redeal patterns
# - Play 1 trick then redeal
# - Start play but redeal before opening lead
# - Play full hand, then deal next hand
# ‚úÖ PASS: All scenarios show 13 cards per position
```

#### User Verification Needed
Please test:
1. [ ] Play a hand partway through, then deal a new hand
2. [ ] After bidding on new hand, click "Show All Hands"
3. [ ] Verify all 4 positions show exactly 13 cards
4. [ ] Verify the hands are from the CURRENT deal (not previous)
5. [ ] Repeat with different play/redeal patterns
6. [ ] Mark as ‚úîÔ∏è VERIFIED if all tests pass

---

## üü° HIGH PRIORITY BUGS (Fix Before Launch)

### BUG-H001: AI Level Display Mismatch (Selected vs Active)
**Status:** üî¥ Active
**Severity:** HIGH - User sees wrong AI difficulty
**Discovered:** 2025-10-18
**Area:** Frontend State Management / AI Selection
**Documentation:** [AI_LEVEL_BUGS_2025-10-18.md](AI_LEVEL_BUGS_2025-10-18.md#bug-1-ai-level-mismatch---selected-vs-active-priority-1)

#### Problem
- User has "Intermediate" (7.5/10) selected in AI Level dropdown button
- DDS Status Indicator shows "DDS Expert AI Active" (9/10)
- Actual AI behavior matches Expert (9/10), not Intermediate

#### Symptoms
- Button shows one difficulty, DDS Status shows another
- After page refresh, selected button doesn't match backend state
- User thinks they're playing against weaker AI than they actually are

#### Root Cause
Frontend component initializes with hardcoded `'intermediate'` default before fetching actual difficulty from backend. Race condition or state update doesn't propagate to UI button.

#### How to Test if Bug is Fixed
```bash
# 1. Start application
cd backend && python3 server.py
cd frontend && npm start

# 2. Load page and start play phase
# Open http://localhost:3000
# Click "Play Random Hand"

# 3. Check AI difficulty displays
# Look at AI Difficulty Selector button
# Look at DDS Status Indicator
# ‚úÖ PASS: Both show same difficulty level
# ‚ùå FAIL: Button shows "Intermediate" but Status shows "Expert"

# 4. Refresh page
# Press F5 to reload
# ‚úÖ PASS: Button shows same difficulty as before refresh
# ‚ùå FAIL: Button resets to default despite backend having different value
```

#### Files Involved
- `frontend/src/components/AIDifficultySelector.jsx` (line 38) - Hardcoded default
- `frontend/src/components/DDSStatusIndicator.jsx` - Status display
- `backend/core/session_state.py` (lines 47-72) - Backend default logic

---

### BUG-H002: Expert AI Discards High Cards (Kings) When Low Cards Available
**Status:** ‚úÖ RESOLVED - Fixed with discard penalty in minimax AI (2025-10-18)
**Severity:** HIGH - AI appears broken, user trust lost
**Discovered:** 2025-10-18
**Last Occurrence:** 2025-10-18 (Trick 5, NT contract, East discarded K‚ô£)
**Fixed:** 2025-10-18 - Added explicit discard penalty for honor cards
**Area:** Card Play AI / Minimax Evaluation / NT Discard Logic
**Documentation:** [DISCARD_BUG_FIX_COMPLETE.md](DISCARD_BUG_FIX_COMPLETE.md), [BUG_ANALYSIS_AND_FIX_SUMMARY.md](BUG_ANALYSIS_AND_FIX_SUMMARY.md), [BUG_H002_KING_DISCARD_ANALYSIS.md](BUG_H002_KING_DISCARD_ANALYSIS.md)

#### Problem
Expert AI (8/10, 9/10) discarded high-value cards (Kings, Queens) when low cards from weak suits were available.

**Root Cause:** The evaluation function assigned +0.6 "communication bonus" to Kings (as potential entries), even in discard situations where they had no entry value. This caused minimax to prefer keeping Kings over low cards.

#### Example
- East (Expert AI) void in spades, must discard
- East holds: ‚ô•QT8 ‚ô¶T76 ‚ô£KJT963
- North leads ‚ô†7 (opponent's winning trick)
- **Expected:** Discard ‚ô¶6 or ‚ô¶7
- **Actual (BUG):** Discarded ‚ô£K ‚ùå
- **Fixed:** Now discards ‚ô£2 or low diamond ‚úÖ

#### User Quote
> "How do you explain an 8/10 AI playing a king in this situation. That is not 8/10 play but more like 4/10."

#### Solution Implemented
Added `_calculate_discard_penalty()` method to Minimax AI that applies strong penalties when discarding honors:
- King: -1.5 penalty
- Queen: -1.0 penalty
- Jack: -0.5 penalty
- Ten: -0.2 penalty
- Low cards (2-9): no penalty

This overrides the +0.6 communication bonus and ensures AI prefers discarding low cards.

#### Fixes Applied (All Versions)
‚úÖ AI card validation before playing (previous fix)
‚úÖ Improved discard logic in Minimax AI (previous fix)
‚úÖ Tolerance-based tiebreaker to prefer low cards (previous fix)
‚úÖ DDS fallback heuristics improved (previous fix)
‚úÖ **NEW: Explicit discard penalty for honor cards** (2025-10-18)

#### How to Test if Bug is Fixed
```bash
# Run automated test (original scenario)
PYTHONPATH=backend python3 test_discard_fix.py
# ‚úÖ PASS: Output shows "‚úÖ ALL TESTS PASSED - AI correctly discards low cards"
# ‚úÖ PASS: AI chose ‚ô£2 (not ‚ô£K)

# Run trick 5 NT test (user's specific scenario)
PYTHONPATH=backend python3 test_trick5_nt_discard.py
# ‚úÖ PASS: AI chose 2‚ô£ instead of K‚ô£

# Manual test: Play 10 hands at Expert level
# 1. Start app, set AI to "Expert" (9/10)
# 2. Play 10 random hands
# 3. Watch for any discard situations (when AI is void in led suit)
# 4. ‚úÖ PASS: AI discards low cards (2-7) in 100% of cases
```

#### Files Modified
- `backend/engine/play/ai/minimax_ai.py` (lines 153-157, 490-526) - **NEW: Discard penalty**
- `backend/engine/play/ai/minimax_ai.py` (lines 364-430, 167-208) - Previous fixes
- `backend/engine/play/ai/dds_ai.py` (lines 380-412) - Previous fixes
- `backend/server.py` (lines 1583-1615) - Validation (previous fix)

#### Tests Added
- `test_discard_fix.py` - Original test case (now passes)
- `test_trick5_nt_discard.py` - **NEW: User's specific trick 5 scenario** (passes)

---

### BUG-H003: First Hand After Server Restart - Illegal Bidding Sequence
**Status:** üî¥ Active (Intermittent)
**Severity:** HIGH - First impression is broken game
**Discovered:** 2025-10-10
**Area:** Bidding Engine / State Management
**Documentation:** [PRODUCTION_BUGS_AND_TEST_PLAN.md](PRODUCTION_BUGS_AND_TEST_PLAN.md#bug-002-first-hand-after-server-startup---illegal-bidding-sequence)

#### Problem
On the **first hand dealt after server startup**, all three AI players sometimes bid identically (e.g., all bid 1NT), which violates bridge rules.

#### Example
```
Auction: [1NT, 1NT, 1NT, Pass]
- North: 1NT (17 HCP, balanced) ‚úÖ Legal
- East: 1NT (9 HCP, balanced) ‚ùå ILLEGAL - should Pass
- South: 1NT (8 HCP) ‚ùå ILLEGAL - can't bid same level
- West: Pass ‚úÖ Legal
```

#### Evidence
All three AI players received **North's hand data** instead of their own hands during bidding.

#### How to Test if Bug is Fixed
```bash
# Test requires server restart
# 1. Stop backend
pkill -f "python.*server.py"

# 2. Clear session data
rm backend/bridge.db  # Optional: clears session state

# 3. Start backend
cd backend
python3 server.py

# 4. Start frontend
cd frontend
npm start

# 5. Deal FIRST hand after restart
# Open http://localhost:3000
# Click "Deal New Hand"
# Watch first 4 bids carefully

# ‚úÖ PASS: Each player bids according to their own hand
#          No duplicate bids at same level
#          Bids are legal given hand HCP
# ‚ùå FAIL: All three AI players bid the same thing (e.g., all 1NT)

# 6. Repeat test 10 times (it's intermittent)
# Stop server, restart, deal first hand, observe bidding
# ‚úÖ PASS: 10/10 hands have legal bidding sequences
# ‚ùå FAIL: Any hand shows duplicate bids
```

#### Files Involved
- `backend/server.py` - `/api/get-next-bid` endpoint
- `frontend/src/App.js` - AI bidding loop
- `backend/core/session_state.py` - Deal storage

---

## üü¢ MEDIUM PRIORITY BUGS (Fix Soon)

### BUG-M001: Declarer's Hand Not Visible When User is Dummy
**Status:** ‚úÖ Fixed (2025-10-18)
**Severity:** MEDIUM - Game breaking in specific scenario
**Discovered:** 2025-10-18
**Area:** Card Play Display
**Documentation:** [BUG_FIX_DECLARER_HAND_NOT_VISIBLE_2025-10-18.md](BUG_FIX_DECLARER_HAND_NOT_VISIBLE_2025-10-18.md)

#### Problem
When user (South) is dummy and another position (North) is declarer, the declarer's hand was not displaying on screen.

#### Scenario
- Contract: 3NT by North (North is declarer)
- South is dummy (user position)
- User should see AND control North's cards
- **Bug:** North's hand was not displaying at all

#### Fix Applied
Updated App.js to use `visible_hands` data structure that backend already provides. No longer makes separate API call that was failing.

#### How to Test if Bug is Fixed
```bash
# 1. Start app
cd backend && python3 server.py
cd frontend && npm start

# 2. Play hands until you get scenario where North declares
# (or force it by making North open strong and become declarer)

# When North is declarer and South is dummy:
# ‚úÖ PASS: You see both North's hand (top) and South's hand (bottom)
# ‚úÖ PASS: You can click cards in North's hand to play them
# ‚úÖ PASS: Both hands update as cards are played
# ‚ùå FAIL: North's hand is missing/blank

# Edge case: Test when East or West declares
# ‚úÖ PASS: Dummy hand still displays correctly
```

#### Files Modified
- `frontend/src/App.js` (4 locations: lines 347-372, 832-851, 888-907, 1095-1121)

**Status:** ‚úÖ Code fixed, needs user verification

---

### BUG-M002: Replay Hand Button Crashes - "Position W has no cards"
**Status:** ‚úÖ Fixed (2025-10-16)
**Severity:** MEDIUM - Replay feature broken
**Discovered:** 2025-10-16
**Area:** Replay Functionality / State Management
**Documentation:** [REPLAY_BUG_FIX_2025-10-16.md](REPLAY_BUG_FIX_2025-10-16.md)

#### Problem
When pressing "Replay Hand" button after completing a hand, the application crashes with error:
```
AI play failed: Position W has no cards in hand - possible state corruption
```

#### Root Cause
Review request captured hand state **after all 13 tricks completed**, resulting in all players having empty hands. Backend didn't preserve original 13-card deal before play began.

#### Fix Applied
Added `original_deal` field to SessionState that preserves original 13-card hands before play begins. Replay functionality now uses this preserved state.

#### How to Test if Bug is Fixed
```bash
# 1. Start app and play a complete hand
cd backend && python3 server.py
cd frontend && npm start

# 2. Play through all 13 tricks until hand is complete
# Let AI play all positions for speed, or play yourself

# 3. After hand completes, click "Replay Hand" button
# ‚úÖ PASS: Hand restarts with all 13 cards in each position
# ‚úÖ PASS: Can play through entire hand again
# ‚úÖ PASS: Can replay multiple times
# ‚ùå FAIL: Error message "Position W has no cards"
# ‚ùå FAIL: Crash or blank screen

# 4. Test with "Play Random Hand" as well
# Click "Play Random Hand" ‚Üí Complete hand ‚Üí Click "Replay Hand"
# ‚úÖ PASS: Replay works
```

#### Files Modified
- `backend/core/session_state.py` - Added `original_deal` field
- `backend/server.py` (lines 1003-1048, 1178-1184) - Preserve and restore logic
- `frontend/src/App.js` (lines 850-853) - Pass `replay: true` flag

**Status:** ‚úÖ Code fixed, needs user verification

---

### BUG-M003: Hand Display Data Presentation Confusion
**Status:** üî¥ Active (Documentation improvement needed)
**Severity:** MEDIUM - Confusing but not broken
**Discovered:** 2025-10-18
**Area:** Review Data / Hand Display
**Documentation:** [BUG_REPORT_IMPOSSIBLE_CARD_PLAY_2025-10-18.md](BUG_REPORT_IMPOSSIBLE_CARD_PLAY_2025-10-18.md#secondary-issue-confusing-data-presentation)

#### Problem
Review request data is confusing because it shows hand state in two different ways:
1. **Hand.cards** - Current cards in hand (updated as cards played)
2. **Hand.suit_hcp** - HCP from original 13-card deal (immutable)

This makes it **appear** like a player played a card they didn't have.

#### Example
```
Trick 2: East discarded ‚ô£K

Review Data (requested after trick):
  East's cards: ‚ô†A5 ‚ô•QT8 ‚ô¶T76 ‚ô£JT963  ‚Üê No King!
  East's suit_hcp: ‚ô£: 4  ‚Üê 4 HCP = K+J (suggests King exists)

User thinks: "East played ‚ô£K but doesn't have it!"
Reality: East HAD ‚ô£K originally, played it, now removed from cards list
```

#### How to Test if Bug is Fixed
After fix is implemented, review data should clearly show:
```
East's Hand Review:
  Original (13 cards): ‚ô†A5 ‚ô•QT8 ‚ô¶T76 ‚ô£KJT9632
  Played so far (2 cards): ‚ô£K, ‚ô£2
  Current (11 cards): ‚ô†A5 ‚ô•QT8 ‚ô¶T76 ‚ô£JT963
  HCP (original): 11

‚úÖ PASS: Clear separation of original vs current vs played
‚úÖ PASS: Note explaining HCP reflects original deal
‚ùå FAIL: Still confusing which cards were played
```

#### Proposed Fix
Add played cards tracking to Hand class and improve review display to show original/current/played cards separately.

---

## üü¢ LOW PRIORITY BUGS (Nice to Have)

### BUG-L001: 5 Play Tests Failing - Hand Parser Creates 14-Card Hands
**Status:** üî¥ Active
**Severity:** LOW - Test failures only, no production impact
**Discovered:** 2025-10-12
**Area:** Test Infrastructure
**Documentation:** [PRODUCTION_BUGS_AND_TEST_PLAN.md](PRODUCTION_BUGS_AND_TEST_PLAN.md#bug-004-5-play-tests-failing---hand-parser-issue)

#### Problem
5 play engine tests fail because test helper function creates 14-card hands instead of 13-card hands.

**Failing Tests:**
- Some in `tests/play/test_evaluation.py`
- Some in `tests/play/test_minimax_ai.py`

**Note:** This does NOT affect production gameplay, only test helpers.

#### How to Test if Bug is Fixed
```bash
# Run play tests
cd backend
python3 -m pytest tests/play/ -v

# ‚úÖ PASS: 45/45 tests passing (100%)
# ‚ùå FAIL: Still shows 40/45 passing with hand parsing errors
```

#### Files Involved
- `tests/play_test_helpers.py` - `parse_hand()` function

---

### BUG-L002: DDS Status Display Order Mismatch
**Status:** üî¥ Active
**Severity:** LOW - Cosmetic inconsistency
**Discovered:** 2025-10-18
**Area:** Frontend UI Display
**Documentation:** [AI_LEVEL_BUGS_2025-10-18.md](AI_LEVEL_BUGS_2025-10-18.md#bug-2-dds-status-display-order-mismatch)

#### Problem
AI difficulty levels shown in DDS Status Indicator dropdown don't match the order in the AI Difficulty Selector button.

**Button Order (desired):**
1. üå± Beginner (6/10)
2. üìö Intermediate (7.5/10)
3. üéØ Advanced (8/10)
4. üèÜ Expert (9/10)

**DDS Status Order (current):**
- Uses `Object.entries()` which doesn't guarantee order
- May appear in random order

#### How to Test if Bug is Fixed
```bash
# 1. Open app and start play phase
# 2. Click DDS Status Indicator to expand dropdown
# 3. Look at difficulty levels listed

# ‚úÖ PASS: Levels appear in order: Beginner, Intermediate, Advanced, Expert
# ‚úÖ PASS: Same order as in AI Difficulty Selector button
# ‚ùå FAIL: Levels in different order or random order
```

#### Files Involved
- `frontend/src/components/DDSStatusIndicator.jsx` (line 111)

---

## ‚úîÔ∏è VERIFIED BUGS (Fixed and User Confirmed)

### BUG-V001: AI Auto-Bidding for User Position (Race Condition)
**Status:** ‚úîÔ∏è Verified
**Severity:** HIGH (was)
**Fixed:** 2025-10-17
**Verified:** 2025-10-17
**Area:** Bidding UI / AI Control
**Documentation:** [USER_CONTROL_FIXES_2025-10-17.md](USER_CONTROL_FIXES_2025-10-17.md#fix-1-ai-auto-bidding-for-user-position)

#### Problem
AI was occasionally making bids for South (user's position) due to race condition.

#### Fix
Two-layer defense in `App.js`:
1. Early exit check before AI bidding logic
2. Defense-in-depth inside async function

#### User Testing Confirmed
‚úÖ User can now bid their own hand in all scenarios
‚úÖ No AI auto-bidding for South position
‚úÖ Works for all dealer positions

---

### BUG-V002: Automatic Play Phase Transition (Removed User Control)
**Status:** ‚úîÔ∏è Verified
**Severity:** MEDIUM (was)
**Fixed:** 2025-10-17
**Verified:** 2025-10-17
**Area:** User Control / UI Flow
**Documentation:** [USER_CONTROL_FIXES_2025-10-17.md](USER_CONTROL_FIXES_2025-10-17.md#fix-2-automatic-transition-from-bidding-to-playing)

#### Problem
After bidding completed, system automatically transitioned to play phase after 3 seconds, preventing users from reviewing contract.

#### Fix
Removed automatic transition. User must click "Play This Hand" button to start playing.

#### User Testing Confirmed
‚úÖ "Play This Hand" button appears after bidding ends
‚úÖ No automatic countdown to play phase
‚úÖ User controls when to start playing

---

### BUG-V003: AI Card Play Validation Missing
**Status:** ‚úîÔ∏è Verified
**Severity:** CRITICAL (was)
**Fixed:** 2025-10-18
**Verified:** 2025-10-18
**Area:** Card Play Engine
**Documentation:** [BUG_REPORT_IMPOSSIBLE_CARD_PLAY_2025-10-18.md](BUG_REPORT_IMPOSSIBLE_CARD_PLAY_2025-10-18.md#fixes-implemented)

#### Problem
No validation that AI-chosen card was actually in hand before playing it. If AI had bug and returned invalid card, game state would become corrupted.

#### Fix
Added comprehensive validation in `server.py` (lines 1583-1615):
- Validates card is in hand
- Validates card is legal (follow suit rules)
- Only then plays card

#### User Testing Confirmed
‚úÖ No more "impossible card" plays
‚úÖ Clear error messages if AI has bugs
‚úÖ Game state protected from corruption

---

### BUG-V004: Minimax AI Inverted Logic for Defenders
**Status:** ‚úîÔ∏è Verified
**Severity:** CRITICAL (was)
**Fixed:** 2025-10-18
**Verified:** 2025-10-18
**Area:** Card Play AI / Minimax
**Documentation:** [CRITICAL_BUG_FIX_2025-10-18.md](CRITICAL_BUG_FIX_2025-10-18.md)

#### Problem
Minimax maximization/minimization logic was inverted for defenders, causing them to choose losing plays over winning plays.

#### Example
- North to play: 7‚ô£ (wins trick), 5‚ô£, 2‚ô£ (loses trick)
- Evaluation: 7‚ô£ = -2.82, 2‚ô£ = -4.83
- **Before Fix:** AI chose 2‚ô£ (minimized, chose worse score)
- **After Fix:** AI chose 7‚ô£ (maximized, chose better score)

#### User Testing Confirmed
‚úÖ Defenders now correctly choose winning plays
‚úÖ AI plays at intended 8/10 level
‚úÖ No more "stupidly wrong" plays

---

### BUG-V005: Missing Master Trump Detection
**Status:** ‚úîÔ∏è Verified
**Severity:** CRITICAL (was)
**Fixed:** 2025-10-18
**Verified:** 2025-10-18
**Area:** Card Play AI / Evaluation
**Documentation:** [CRITICAL_BUG_FIX_2025-10-18.md](CRITICAL_BUG_FIX_2025-10-18.md#bug-report-2-missing-master-trump-detection)

#### Problem
AI didn't recognize master trumps - trump cards guaranteed to win when opponents void or don't have higher trumps.

#### Example
- East has A‚ô† (only trump left), opponents void in spades
- **Before Fix:** Sure winners = 0.50 (counted as "somewhat reliable")
- **After Fix:** Sure winners = 1.50 (recognized as master trump)

#### User Testing Confirmed
‚úÖ AI recognizes master trumps correctly
‚úÖ Doesn't waste high cards when holding masters
‚úÖ Improved play quality in trump contracts

---

### BUG-V006: Scoring System Reversed Penalties (Negative vs Positive)
**Status:** ‚úîÔ∏è Verified
**Severity:** HIGH (was)
**Fixed:** 2025-10-18
**Verified:** 2025-10-18
**Area:** Scoring System / Session Management
**Documentation:** [SCORING_FIX_SUMMARY.md](SCORING_FIX_SUMMARY.md)

#### Problem
Session scoring system had positive/negative points reversed. When declaring side went down (failed to make contract), the negative penalty was incorrectly added to their score instead of giving positive penalty points to the defending side.

#### Example
- NS declares 3NT, goes down 1
- **Before Fix (WRONG):** NS gets -50, EW gets 0
- **After Fix (CORRECT):** NS gets 0, EW gets +50 (defenders' reward)

#### Root Cause
In `session_manager.py`, the `add_hand_score()` method was simply adding the score (positive or negative) to the declaring side without checking if the contract was made or defeated.

#### Fix Applied
Updated `add_hand_score()` to correctly assign points:
- If score >= 0 (contract made): Points go to declaring side
- If score < 0 (contract defeated): Penalty points go to defending side

#### User Testing Confirmed
‚úÖ Positive points always mean "winning the hand"
‚úÖ Setting opponents (defeating their contract) gives positive points
‚úÖ Session totals correctly reflect who is winning
‚úÖ All 6 session scoring tests pass
‚úÖ All 43 existing scoring tests still pass

#### Files Modified
- `backend/engine/session_manager.py` (lines 52-93) - Fixed penalty assignment
- `backend/test_session_scoring.py` (NEW) - Comprehensive test suite

---

## üìä Bug Summary Statistics

### By Status
- üî¥ Active: 6 bugs (includes **BUG-C004** ‚¨ÖÔ∏è NEW)
- üîÑ In Progress: 1 bug (BUG-H002)
- ‚úÖ Fixed (awaiting verification): 3 bugs (BUG-M001, BUG-M002, BUG-C002)
- ‚úîÔ∏è Verified (user confirmed): 6 bugs (includes BUG-V006 Scoring)

### By Severity
- üî¥ CRITICAL: 3 bugs (BUG-C001, BUG-C002, **BUG-C004** ‚¨ÖÔ∏è NEW)
- üü° HIGH: 3 bugs (BUG-H001, H002, H003)
- üü¢ MEDIUM: 3 bugs (BUG-M001, M002, M003)
- üü¢ LOW: 2 bugs (BUG-L001, L002)

### By Area
- **Authentication:** 1 bug
- **AI Selection/Display:** 2 bugs
- **Card Play AI / DDS:** 3 bugs
- **Bidding Engine:** 1 bug
- **Display/UI:** 3 bugs
- **State Management:** 3 bugs (**+1 NEW**: BUG-C004 stale play_state)
- **Scoring System:** 1 bug (BUG-V006 - Verified Fixed)
- **Test Infrastructure:** 1 bug

---

## üéØ Next Bug Reporting

When you report a bug in chat, I will:

1. **Assign unique ID** - BUG-[Severity][Number] (e.g., BUG-H004)
2. **Document thoroughly:**
   - Problem description
   - Symptoms user sees
   - Root cause analysis (if known)
   - Files involved
3. **Create test plan** - Step-by-step instructions to verify fix
4. **Track status** - From üî¥ Active ‚Üí ‚úÖ Fixed ‚Üí ‚úîÔ∏è Verified
5. **Cross-reference** - Link to detailed bug report files

---

## üìù Bug Reporting Template

```markdown
### BUG-[ID]: [Short Title]
**Status:** üî¥ Active
**Severity:** [CRITICAL/HIGH/MEDIUM/LOW]
**Discovered:** YYYY-MM-DD
**Area:** [Component/Feature]
**Documentation:** [Link to detailed doc if exists]

#### Problem
[What's broken from user perspective]

#### Symptoms
- [What user sees/experiences]
- [Error messages]
- [Incorrect behavior]

#### Root Cause
[Why it's happening - if known]

#### How to Test if Bug is Fixed
[Step-by-step user testing instructions]
‚úÖ PASS criteria
‚ùå FAIL criteria

#### Files Involved
- `path/to/file.py` (line X) - Description
```

---

**Last Updated:** 2026-02-01
**Total Bugs Tracked:** 17 (14 original + BUG-C002 DDS Crash + BUG-V006 Scoring + BUG-C003 Last Trick Freeze + BUG-C004 Stale Play State)
**Critical Blockers:** 3 (BUG-C001, BUG-C002, BUG-C004) ‚Äî BUG-C003 fixed, awaiting verification
**Verified Fixed:** 6 bugs (including BUG-V006 Scoring)
**Production Ready:** ‚ö†Ô∏è After BUG-C001, BUG-C002, and BUG-C004 fixed, BUG-C003 verification pending
